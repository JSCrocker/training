{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd5fc02d-b234-45b8-bd63-605c9f0abf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.80.128:4040\n",
       "SparkContext available as 'sc' (version = 3.1.3, master = local[*], app id = local-1648486590487)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ordersDf: org.apache.spark.sql.DataFrame = [key: binary, value: binary ... 5 more fields]\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var ordersDf = spark.readStream\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n",
    "    .option(\"subscribe\", \"orders-5-min\")\n",
    "    .option(\"group.id\", \"orders-5-min-jsc\")\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e7f5423-f828-444d-b667-d2d2dd91efb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ordersDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a7ed58-bf40-4541-90a1-bf03a6e3f745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ticksDf: org.apache.spark.sql.DataFrame = [value: string, timestamp: timestamp]\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ticksDf = ordersDf.selectExpr(\"CAST(value AS STRING)\", \"timestamp\")\n",
    "ticksDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b48cc185-523e-42e3-8268-d67ffe8c2b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types.{DoubleType, IntegerType, LongType, TimestampType, StringType, StructField, StructType}\n",
       "import org.apache.spark.sql.functions._\n",
       "schema: org.apache.spark.sql.types.StructType = StructType(StructField(orderId,IntegerType,true), StructField(itemId,StringType,true), StructField(quantity,IntegerType,true), StructField(unitprice,IntegerType,true), StructField(state,StringType,true), StructField(timestamp,LongType,true))\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{DoubleType, IntegerType, LongType, TimestampType,  StringType, StructField, StructType}\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val schema = StructType(\n",
    "    List(\n",
    "      StructField(\"orderId\", IntegerType, true),\n",
    "      StructField(\"itemId\", StringType, true),\n",
    "      StructField(\"quantity\", IntegerType, true),\n",
    "      StructField(\"unitprice\", IntegerType, true),\n",
    "      StructField(\"state\", StringType, true),\n",
    "      StructField(\"timestamp\", LongType, true)\n",
    "    )\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaf3fbdd-1011-4360-aec5-6cdbfbed5138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: struct (nullable = true)\n",
      " |    |-- orderId: integer (nullable = true)\n",
      " |    |-- itemId: string (nullable = true)\n",
      " |    |-- quantity: integer (nullable = true)\n",
      " |    |-- unitprice: integer (nullable = true)\n",
      " |    |-- state: string (nullable = true)\n",
      " |    |-- timestamp: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "jsonDf: org.apache.spark.sql.DataFrame = [value: struct<orderId: int, itemId: string ... 4 more fields>, timestamp: timestamp]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val jsonDf = ticksDf.withColumn(\"value\", from_json($\"value\", schema))\n",
    "jsonDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80f646b3-13b6-4141-8788-8fe2c5c1c7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- orderId: integer (nullable = true)\n",
      " |-- itemId: string (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- unitprice: integer (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "stockTickDf: org.apache.spark.sql.DataFrame = [orderId: int, itemId: string ... 4 more fields]\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var stockTickDf = jsonDf.select(col(\"value.*\"))\n",
    "stockTickDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d99593d1-63be-4952-a723-e694be8408d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- orderId: integer (nullable = true)\n",
      " |-- itemId: string (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- unitprice: integer (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- total: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "stockTickDf: org.apache.spark.sql.DataFrame = [orderId: int, itemId: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stockTickDf = stockTickDf.withColumn(\"total\", col(\"unitprice\") * col(\"quantity\"))\n",
    "stockTickDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f1807e2-74e5-46cc-9197-601e631f706b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stockTickDf: org.apache.spark.sql.DataFrame = [orderId: int, itemId: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stockTickDf = stockTickDf\n",
    "                .withColumn(\"timestampTemp\", (col(\"timestamp\") / 1000).cast(\"timestamp\"))\n",
    "                .withColumn(\"trade_time\", date_trunc(\"minute\", col(\"timestampTemp\")))\n",
    "                .drop(\"timestamp\")\n",
    "                .drop(\"timestampTemp\")\n",
    "                .withColumnRenamed(\"trade_time\", \"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b888f9cc-3a16-48ce-8b41-d4e6597edbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- orderId: integer (nullable = true)\n",
      " |-- itemId: string (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- unitprice: integer (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- total: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stockTickDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe55500-bc89-4d71-b436-bc4c83aeff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "//import org.apache.spark.sql.expressions.Window\n",
    "//import org.apache.spark.sql.Column\n",
    "\n",
    "//val stockTickDf5Min = stockTickDf.groupBy(\"symbol\", window(\"timestamp\", \"300 seconds\"))\n",
    "                            \n",
    "//stockTickDf5Min.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ec842c9-fa0e-4885-b86f-c9cbd1d29dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "echoOnconsole: org.apache.spark.sql.streaming.StreamingQuery = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@7b19bd04\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-------+------+--------+---------+-----+-----+---------+\n",
      "|orderId|itemId|quantity|unitprice|state|total|timestamp|\n",
      "+-------+------+--------+---------+-----+-----+---------+\n",
      "+-------+------+--------+---------+-----+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val echoOnconsole = stockTickDf\n",
    "                .writeStream\n",
    "                .outputMode(\"update\")\n",
    "                .format(\"console\")\n",
    "                .option(\"truncate\", false)\n",
    "                .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6580ce8d-e51e-47b9-aa84-c7d7dec69eb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "28: error: not found: value stockTickDf1Min",
     "output_type": "error",
     "traceback": [
      "<console>:28: error: not found: value stockTickDf1Min",
      "       val stockTickDf5MinKafka = stockTickDf1Min.selectExpr(\"to_json(struct(*)) AS value\")",
      "                                  ^",
      ""
     ]
    }
   ],
   "source": [
    "val stockTickDf5MinKafka = stockTickDf5Min.selectExpr(\"to_json(struct(*)) AS value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9360d1d-5f05-4392-813e-5818aff871b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stockTickDf1MinKafka\\\n",
    "            .writeStream\\\n",
    "             .format(\"kafka\")\\\n",
    "            .outputMode(\"update\")\\\n",
    "             .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\\\n",
    "            .option(\"topic\", \"candles-1min\")\\\n",
    "            .option(\"checkpointLocation\", \"file:///tmp/spark3\")\\\n",
    "            .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f2c495-4571-406a-bb76-4d02610345a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Question 2 Part b. publish to Amazon RDS table using JDBC in append mode\n",
    "// import org.apache.spark.sql._\n",
    "\n",
    "// def processBatchData(ordersBatchDf: DataFrame, batch_id: Long) = {\n",
    "//     print (\"process batch called\", batch_id, \"writing \", ordersBatchDf.count())\n",
    "\n",
    "//      val ordersBatchFinalDf = (ordersBatchDf\n",
    "//         .write\n",
    "//         .select(col(\"state\"), col(\"total\"))\n",
    "//         .mode(\"append\")\n",
    "//         .format(\"jdbc\")\n",
    "//         .option(\"url\", \"jdbc:mysql-database-1.cgioa4qvqncf.us-east-2.rds.amazonaws.com\")\n",
    "//         .option(\"driver\", \"com.mysql.jdbc.Driver\")\n",
    "//         .option(\"user\", \"admin\")\n",
    "//         .option(\"password\", \"FtgY3XcBn0i\")\n",
    "//         .option(\"dbtable\", \"orders_5min\")\n",
    "//         .save()\n",
    "//     )\n",
    "// }\n",
    "// stockTickDf.writeStream.outputMode(\"append\").foreachBatch(processBatchData).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7cdd84-7f1f-41e1-8fc5-841a1f368365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
