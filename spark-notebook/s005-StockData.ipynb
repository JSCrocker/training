{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f833c9d2-8022-4880-acd4-138b466563c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.80.128:4040\n",
       "SparkContext available as 'sc' (version = 3.1.3, master = local[*], app id = local-1647440248781)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Company Name: string (nullable = true)\n",
      " |-- Industry: string (nullable = true)\n",
      " |-- Symbol: string (nullable = true)\n",
      " |-- Series: string (nullable = true)\n",
      " |-- ISIN Code: string (nullable = true)\n",
      "\n",
      "+------------------+------------------+----------+------+------------+\n",
      "|      Company Name|          Industry|    Symbol|Series|   ISIN Code|\n",
      "+------------------+------------------+----------+------+------------+\n",
      "|    Axis Bank Ltd.|FINANCIAL SERVICES|  AXISBANK|    EQ|INE238A01034|\n",
      "|Bajaj Finance Ltd.|FINANCIAL SERVICES|BAJFINANCE|    EQ|INE296A01024|\n",
      "+------------------+------------------+----------+------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sectorDf: org.apache.spark.sql.DataFrame = [Company Name: string, Industry: string ... 3 more fields]\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sectorDf = spark.read\n",
    "                    .format(\"csv\")\n",
    "                    .option(\"header\", true)\n",
    "                    .option(\"inferSchema\", true)\n",
    "                    .option(\"delimitter\", \",\")\n",
    "                    .load(\"hdfs://localhost:9000/stocks/sectors\")\n",
    "\n",
    "sectorDf.printSchema()\n",
    "sectorDf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79acfec7-c624-4d94-99a9-58c04a8222b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types.{StringType, StructType, DoubleType, IntegerType, LongType, StructField}\n",
       "SectorSchema: org.apache.spark.sql.types.StructType = StructType(StructField(Company,StringType,true), StructField(Industry,StringType,true), StructField(Symbol,StringType,true), StructField(Series,StringType,true), StructField(ISIN,StringType,true))\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// create a schema for dataframe using scala\n",
    "import org.apache.spark.sql.types.{StringType, StructType, DoubleType, IntegerType, LongType, StructField}\n",
    "\n",
    "// SectorSchema\n",
    "val SectorSchema = StructType(\n",
    "                    List(\n",
    "                        StructField(\"Company\", StringType, true), // true nullable\n",
    "                        StructField(\"Industry\", StringType, true),\n",
    "                        StructField(\"Symbol\", StringType, true),\n",
    "                        StructField(\"Series\", StringType, true),\n",
    "                        StructField(\"ISIN\", StringType, true)\n",
    "                        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93677ce9-12a0-4439-beb5-c7d2f232bd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Industry: string (nullable = true)\n",
      " |-- Symbol: string (nullable = true)\n",
      " |-- Series: string (nullable = true)\n",
      " |-- ISIN: string (nullable = true)\n",
      "\n",
      "+------------------+------------------+----------+------+------------+\n",
      "|           Company|          Industry|    Symbol|Series|        ISIN|\n",
      "+------------------+------------------+----------+------+------------+\n",
      "|    Axis Bank Ltd.|FINANCIAL SERVICES|  AXISBANK|    EQ|INE238A01034|\n",
      "|Bajaj Finance Ltd.|FINANCIAL SERVICES|BAJFINANCE|    EQ|INE296A01024|\n",
      "+------------------+------------------+----------+------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sectorDf: org.apache.spark.sql.DataFrame = [Company: string, Industry: string ... 3 more fields]\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sectorDf = spark.read\n",
    "                    .format(\"csv\")\n",
    "                    .option(\"header\", true)\n",
    "                    .option(\"delimitter\", \",\")\n",
    "                    .schema(SectorSchema)\n",
    "                    .load(\"hdfs://localhost:9000/stocks/sectors\")\n",
    "\n",
    "sectorDf.printSchema()\n",
    "sectorDf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54fa8bd6-3155-45b3-90d1-91f6b9ee93f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: Array[String] = Array(Company, Industry, Symbol, Series, ISIN)\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sectorDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93e6760c-3bda-47bb-af5c-aa5081f07c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res3: Long = 200\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sectorDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13005a9e-16e9-4b4f-b91f-82b7d8dd6f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Industry: string (nullable = true)\n",
      " |-- symbol: string (nullable = true)\n",
      "\n",
      "+------------------+----------+\n",
      "|          Industry|    symbol|\n",
      "+------------------+----------+\n",
      "|FINANCIAL SERVICES|  AXISBANK|\n",
      "|FINANCIAL SERVICES|BAJFINANCE|\n",
      "|FINANCIAL SERVICES|BAJAJFINSV|\n",
      "|FINANCIAL SERVICES|  CHOLAFIN|\n",
      "|FINANCIAL SERVICES|   HDFCAMC|\n",
      "+------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [Industry: string, symbol: string]\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = sectorDf.select(\"Industry\", \"symbol\")\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c41a71b5-451a-43bf-85f9-ed87e2a7022e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            Industry|\n",
      "+--------------------+\n",
      "|          AUTOMOBILE|\n",
      "|        CONSTRUCTION|\n",
      "|      CONSUMER GOODS|\n",
      "|  FINANCIAL SERVICES|\n",
      "| HEALTHCARE SERVICES|\n",
      "|INDUSTRIAL MANUFA...|\n",
      "|                  IT|\n",
      "|MEDIA ENTERTAINME...|\n",
      "|              METALS|\n",
      "|           OIL & GAS|\n",
      "|              PHARMA|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// pick all industry and sort them in ascending order\n",
    "// output has ... format this mean columns values are truncated by show() method\n",
    "sectorDf.select(\"Industry\").distinct().sort(\"Industry\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65709d0f-8dba-414f-96c9-8abf99812535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+\n",
      "|Industry                         |\n",
      "+---------------------------------+\n",
      "|AUTOMOBILE                       |\n",
      "|CONSTRUCTION                     |\n",
      "|CONSUMER GOODS                   |\n",
      "|FINANCIAL SERVICES               |\n",
      "|HEALTHCARE SERVICES              |\n",
      "|INDUSTRIAL MANUFACTURING         |\n",
      "|IT                               |\n",
      "|MEDIA ENTERTAINMENT & PUBLICATION|\n",
      "|METALS                           |\n",
      "|OIL & GAS                        |\n",
      "|PHARMA                           |\n",
      "+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// shows full column name\n",
    "sectorDf.select(\"Industry\").distinct().sort(\"Industry\").show(truncate = false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa020208-263d-46ee-a2a9-3085ccb7067b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            Industry|\n",
      "+--------------------+\n",
      "|              PHARMA|\n",
      "|           OIL & GAS|\n",
      "|              METALS|\n",
      "|MEDIA ENTERTAINME...|\n",
      "|                  IT|\n",
      "|INDUSTRIAL MANUFA...|\n",
      "| HEALTHCARE SERVICES|\n",
      "|  FINANCIAL SERVICES|\n",
      "|      CONSUMER GOODS|\n",
      "|        CONSTRUCTION|\n",
      "|          AUTOMOBILE|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.{col, desc}\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{col, desc}\n",
    "\n",
    "// sectorDf(\"Industry\") represent col type\n",
    "// descending order\n",
    "sectorDf.select(sectorDf(\"Industry\")).distinct().sort(desc(\"Industry\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9ac9661-9e07-4010-ba34-2835522cc130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            Industry|\n",
      "+--------------------+\n",
      "|              PHARMA|\n",
      "|           OIL & GAS|\n",
      "|              METALS|\n",
      "|MEDIA ENTERTAINME...|\n",
      "|                  IT|\n",
      "|INDUSTRIAL MANUFA...|\n",
      "| HEALTHCARE SERVICES|\n",
      "|  FINANCIAL SERVICES|\n",
      "|      CONSUMER GOODS|\n",
      "|        CONSTRUCTION|\n",
      "|          AUTOMOBILE|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.{col, desc}\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{col, desc}\n",
    "\n",
    "// col\n",
    "// descending order\n",
    "sectorDf.select(col(\"Industry\")).distinct().sort(desc(\"Industry\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f07391a-cea4-4ee7-9bd9-0e8e7f18faf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            Industry|\n",
      "+--------------------+\n",
      "|              PHARMA|\n",
      "|           OIL & GAS|\n",
      "|              METALS|\n",
      "|MEDIA ENTERTAINME...|\n",
      "|                  IT|\n",
      "|INDUSTRIAL MANUFA...|\n",
      "| HEALTHCARE SERVICES|\n",
      "|  FINANCIAL SERVICES|\n",
      "|      CONSUMER GOODS|\n",
      "|        CONSTRUCTION|\n",
      "|          AUTOMOBILE|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.{col, desc}\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{col, desc}\n",
    "\n",
    "// $ is a special symbol in scala for spark to represent column name\n",
    "// descending order\n",
    "sectorDf.select($\"Industry\").distinct().sort(desc(\"Industry\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b3a74fc-c46a-4d45-8473-6635f4472c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SYMBOL: string (nullable = true)\n",
      " |-- SERIES: string (nullable = true)\n",
      " |-- OPEN: double (nullable = true)\n",
      " |-- HIGH: double (nullable = true)\n",
      " |-- LOW: double (nullable = true)\n",
      " |-- CLOSE: double (nullable = true)\n",
      " |-- LAST: double (nullable = true)\n",
      " |-- PREVCLOSE: double (nullable = true)\n",
      " |-- TOTTRDQTY: integer (nullable = true)\n",
      " |-- TOTTRDVAL: double (nullable = true)\n",
      " |-- TIMESTAMP: timestamp (nullable = true)\n",
      " |-- TOTALTRADES: integer (nullable = true)\n",
      " |-- ISIN: string (nullable = true)\n",
      "\n",
      "+----------+------+----+----+----+-----+-----+---------+---------+-------------+-------------------+-----------+------------+\n",
      "|    SYMBOL|SERIES|OPEN|HIGH| LOW|CLOSE| LAST|PREVCLOSE|TOTTRDQTY|    TOTTRDVAL|          TIMESTAMP|TOTALTRADES|        ISIN|\n",
      "+----------+------+----+----+----+-----+-----+---------+---------+-------------+-------------------+-----------+------------+\n",
      "| 20MICRONS|    EQ|70.1|73.6|70.1|71.85|72.05|     71.2|   219912|1.583125505E7|2022-03-02 00:00:00|       2642|INE144J01027|\n",
      "|21STCENMGM|    EQ|29.6|29.6|29.6| 29.6| 29.6|     30.2|     1209|      35786.4|2022-03-02 00:00:00|         45|INE253B01015|\n",
      "+----------+------+----+----+----+-----+-----+---------+---------+-------------+-------------------+-----------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "stockDf: org.apache.spark.sql.DataFrame = [SYMBOL: string, SERIES: string ... 11 more fields]\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var stockDf = spark.read\n",
    "                    .format(\"csv\")\n",
    "                    .option(\"header\", true)\n",
    "                    .option(\"inferSchema\", true)\n",
    "                    .option(\"delimitter\", \",\")\n",
    "                    .option(\"timestampFormat\", \"dd-MMM-yyyy\")\n",
    "                    .load(\"hdfs://localhost:9000/stocks/daily\")\n",
    "                    .drop(\"_c13\")\n",
    "\n",
    "stockDf.printSchema()\n",
    "stockDf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7822326a-d6b0-4c90-b6a0-31fba49ec375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|    SYMBOL|TOTTRDQTY|\n",
      "+----------+---------+\n",
      "|ADANIPOWER| 37990829|\n",
      "|  ALOKINDS| 13696536|\n",
      "| AMBUJACEM|  6623505|\n",
      "|  ASHOKLEY| 13299580|\n",
      "|       AWL| 13334439|\n",
      "|  AXISBANK| 11691602|\n",
      "|BANDHANBNK|  7537231|\n",
      "|BANKBARODA| 47475131|\n",
      "|       BEL| 17202697|\n",
      "|BHARTIARTL| 10220908|\n",
      "|      BHEL| 33734292|\n",
      "|    BIOCON| 13122596|\n",
      "|      BPCL|  7734602|\n",
      "|     CANBK| 10972135|\n",
      "| COALINDIA| 72648396|\n",
      "|   CPSEETF|  6838326|\n",
      "|   DEVYANI|  5606901|\n",
      "|     DHANI| 37519005|\n",
      "|       DLF|  6854294|\n",
      "| FCONSUMER| 11838948|\n",
      "+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// get the stocks where volume is greater than 5 million\n",
    "stockDf.filter($\"TOTTRDQTY\" > 5000000).select(\"SYMBOL\", \"TOTTRDQTY\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fe28189-22ef-45aa-b2d7-8766d919e4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----------------+\n",
      "|    SYMBOL|TOTTRDQTY|        TOTTRDVAL|\n",
      "+----------+---------+-----------------+\n",
      "|ADANIPOWER| 37990829|  4.70183548235E9|\n",
      "|  ALOKINDS| 13696536|   3.3159322015E8|\n",
      "| AMBUJACEM|  6623505|  2.02519921995E9|\n",
      "|  ASHOKLEY| 13299580|  1.56376581585E9|\n",
      "|       AWL| 13334439|   5.1355806697E9|\n",
      "|  AXISBANK| 11691602|   8.6334568352E9|\n",
      "|BANDHANBNK|  7537231|   2.2247190949E9|\n",
      "|BANKBARODA| 47475131|  4.91196164495E9|\n",
      "|       BEL| 17202697|   3.7135653097E9|\n",
      "|BHARTIARTL| 10220908|  6.87781912745E9|\n",
      "|      BHEL| 33734292|   1.6971618874E9|\n",
      "|    BIOCON| 13122596|   4.5562065457E9|\n",
      "|      BPCL|  7734602|    2.678648484E9|\n",
      "|     CANBK| 10972135|  2.36614299085E9|\n",
      "| COALINDIA| 72648396|1.313502573215E10|\n",
      "|   CPSEETF|  6838326|   2.2645909145E8|\n",
      "|   DEVYANI|  5606901|    8.953902411E8|\n",
      "|     DHANI| 37519005|  2.89349521655E9|\n",
      "|       DLF|  6854294|  2.36572027835E9|\n",
      "|FEDERALBNK| 15548463|   1.4921710391E9|\n",
      "+----------+---------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// get the stocks where volume is greater than 5 million and traded value (amoount) greater than 100 million\n",
    "stockDf.filter(($\"TOTTRDQTY\" > 5000000) && ($\"TOTTRDVAL\" > 100000000)).select(\"SYMBOL\", \"TOTTRDQTY\", \"TOTTRDVAL\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c95bd63c-2c7b-4f14-b321-0ae75ffacb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SYMBOL: string (nullable = true)\n",
      " |-- SERIES: string (nullable = true)\n",
      " |-- OPEN: double (nullable = true)\n",
      " |-- HIGH: double (nullable = true)\n",
      " |-- LOW: double (nullable = true)\n",
      " |-- CLOSE: double (nullable = true)\n",
      " |-- LAST: double (nullable = true)\n",
      " |-- PREVCLOSE: double (nullable = true)\n",
      " |-- TOTTRDQTY: integer (nullable = true)\n",
      " |-- TOTTRDVAL: double (nullable = true)\n",
      " |-- TIMESTAMP: timestamp (nullable = true)\n",
      " |-- TOTALTRADES: integer (nullable = true)\n",
      " |-- ISIN: string (nullable = true)\n",
      " |-- GAIN: double (nullable = true)\n",
      "\n",
      "+----------+------+-------+-------+-------+-------+-------+---------+---------+-------------+-------------------+-----------+------------+--------------------+\n",
      "|    SYMBOL|SERIES|   OPEN|   HIGH|    LOW|  CLOSE|   LAST|PREVCLOSE|TOTTRDQTY|    TOTTRDVAL|          TIMESTAMP|TOTALTRADES|        ISIN|                GAIN|\n",
      "+----------+------+-------+-------+-------+-------+-------+---------+---------+-------------+-------------------+-----------+------------+--------------------+\n",
      "| 20MICRONS|    EQ|   70.1|   73.6|   70.1|  71.85|  72.05|     71.2|   219912|1.583125505E7|2022-03-02 00:00:00|       2642|INE144J01027|                1.75|\n",
      "|21STCENMGM|    EQ|   29.6|   29.6|   29.6|   29.6|   29.6|     30.2|     1209|      35786.4|2022-03-02 00:00:00|         45|INE253B01015|                 0.0|\n",
      "| 3IINFOLTD|    EQ|  51.05|  51.35|   49.1|  49.45|   49.4|    51.45|  1092731| 5.46426994E7|2022-03-02 00:00:00|       7273|INE748C01038| -1.5999999999999943|\n",
      "|   3MINDIA|    EQ|21480.0|21480.0|20730.0|20923.1|20925.0|  21208.4|     1823|3.829445575E7|2022-03-02 00:00:00|       1120|INE470A01017|  -556.9000000000015|\n",
      "|    3PLAND|    BE|   15.9|  16.15|   14.8|   15.5|  15.65|    15.55|     8318|     128580.0|2022-03-02 00:00:00|         70|INE105C01023|-0.40000000000000036|\n",
      "+----------+------+-------+-------+-------+-------+-------+---------+---------+-------------+-------------------+-----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "stockDf: org.apache.spark.sql.DataFrame = [SYMBOL: string, SERIES: string ... 12 more fields]\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Scala we cause single qoute without closing to represnet column to 'OPEN\n",
    "stockDf = stockDf.withColumn(\"GAIN\", $\"CLOSE\" - 'OPEN)\n",
    "stockDf.printSchema()\n",
    "stockDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44ca4920-2f6c-467d-8b85-1253b6fcb539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----+----+----+-----+-----+---------+---------+-------------+-------------------+-----------+------------+----+----+-----+---+\n",
      "|    SYMBOL|SERIES|OPEN|HIGH| LOW|CLOSE| LAST|PREVCLOSE|TOTTRDQTY|    TOTTRDVAL|          TIMESTAMP|TOTALTRADES|        ISIN|GAIN|Year|Month|Day|\n",
      "+----------+------+----+----+----+-----+-----+---------+---------+-------------+-------------------+-----------+------------+----+----+-----+---+\n",
      "| 20MICRONS|    EQ|70.1|73.6|70.1|71.85|72.05|     71.2|   219912|1.583125505E7|2022-03-02 00:00:00|       2642|INE144J01027|1.75|2022|   03| 02|\n",
      "|21STCENMGM|    EQ|29.6|29.6|29.6| 29.6| 29.6|     30.2|     1209|      35786.4|2022-03-02 00:00:00|         45|INE253B01015| 0.0|2022|   03| 02|\n",
      "+----------+------+----+----+----+-----+-----+---------+---------+-------------+-------------------+-----------+------------+----+----+-----+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.date_format\n",
       "stockDf: org.apache.spark.sql.DataFrame = [SYMBOL: string, SERIES: string ... 15 more fields]\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{date_format}\n",
    "stockDf = stockDf.withColumn(\"Year\", date_format($\"TIMESTAMP\", \"yyyy\"))\n",
    "                .withColumn(\"Month\", date_format($\"TIMESTAMP\", \"MM\"))\n",
    "                .withColumn(\"Day\", date_format($\"TIMESTAMP\", \"dd\"))\n",
    "\n",
    "stockDf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e11878b1-7686-4575-b52a-cf35bbf5221d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res15: Int = 2\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stockDf.rdd.getNumPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29194711-5f47-480c-8814-888906328e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stockDf.write\n",
    "        .partitionBy(\"Year\", \"Month\", \"Day\")\n",
    "        .format(\"parquet\")\n",
    "        .mode(\"overwrite\")\n",
    "        .save(\"hdfs://localhost:9000/stock-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79924359-18d1-4edd-9166-3669139e8c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "allData: org.apache.spark.sql.DataFrame = [SYMBOL: string, SERIES: string ... 15 more fields]\n",
       "res17: Long = 4370\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// read data from all the data from stock-data\n",
    "val allData = spark.read.format(\"parquet\")\n",
    "                    .load(\"hdfs://localhost:9000/stock-data\")\n",
    "\n",
    "allData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7a0ed4e-deca-4be6-bff9-a8a7d29643ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "allData2022: org.apache.spark.sql.DataFrame = [SYMBOL: string, SERIES: string ... 14 more fields]\n",
       "res18: Long = 4370\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val allData2022 = spark.read.format(\"parquet\")\n",
    "                        .load(\"hdfs://localhost:9000/stock-data/Year=2022\")\n",
    "\n",
    "allData2022.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a614ce3-78e1-43f1-a211-c7a5fe4a94e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "allData2022Month03: org.apache.spark.sql.DataFrame = [SYMBOL: string, SERIES: string ... 13 more fields]\n",
       "res19: Long = 4370\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val allData2022Month03 = spark.read.format(\"parquet\")\n",
    "                        .load(\"hdfs://localhost:9000/stock-data/Year=2022/Month=03\")\n",
    "\n",
    "allData2022Month03.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64484d8e-c908-4be2-967c-52ee11cd3b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "allData2022Month03Day02: org.apache.spark.sql.DataFrame = [SYMBOL: string, SERIES: string ... 12 more fields]\n",
       "res20: Long = 2198\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val allData2022Month03Day02 = spark.read.format(\"parquet\")\n",
    "                        .load(\"hdfs://localhost:9000/stock-data/Year=2022/Month=03/Day=02\")\n",
    "\n",
    "allData2022Month03Day02.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885951af-c552-4e21-8076-766cd38c47e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
